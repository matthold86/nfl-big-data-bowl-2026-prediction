{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4d88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1932e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_DIR = Path(\"./data\")\n",
    "    OUTPUT_DIR = Path(\"./outputs\")\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 200\n",
    "    PATIENCE = 30\n",
    "    LEARNING_RATE = 1e-3\n",
    "    \n",
    "    WINDOW_SIZE = 10\n",
    "    HIDDEN_DIM = 128\n",
    "    MAX_FUTURE_HORIZON = 94\n",
    "    \n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(input_df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on the input DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        input_df (pd.DataFrame): Input DataFrame containing raw tracking data\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(input_df, output_df):\n",
    "    \"\"\"\n",
    "    Prepare the input DataFrame for model training.\n",
    "    \n",
    "    Args:\n",
    "        input_df (pd.DataFrame): Input DataFrame containing raw tracking data\n",
    "        output_df (pd.DataFrame): Output DataFrame containing target data\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(train_input, train_output, test_input, test_output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5148ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opponent_proximity_simple(input_df):\n",
    "    \"\"\"Only basic opponent proximity - no complex features\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for (gid, pid), group in tqdm(input_df.groupby(['game_id', 'play_id']), \n",
    "                                   desc=\"üèà Opponent proximity\", leave=False):\n",
    "        last = group.sort_values('frame_id').groupby('nfl_id').last()\n",
    "        \n",
    "        if len(last) < 2:\n",
    "            continue\n",
    "            \n",
    "        positions = last[['x', 'y']].values\n",
    "        sides = last['player_side'].values\n",
    "        speeds = last['s'].values\n",
    "        directions = last['dir'].values\n",
    "        \n",
    "        for i, (nid, side) in enumerate(zip(last.index, sides)):\n",
    "            opp_mask = sides != side\n",
    "            \n",
    "            feat = {\n",
    "                'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n",
    "                'nearest_opp_dist': 50.0,\n",
    "                'num_nearby_opp_3': 0,\n",
    "                'num_nearby_opp_5': 0,\n",
    "                'closing_speed_opp': 0.0,\n",
    "            }\n",
    "\n",
    "            if not opp_mask.any():\n",
    "                features.append(feat)\n",
    "                continue\n",
    "            \n",
    "            opp_positions = positions[opp_mask]\n",
    "            distances = np.sqrt(((positions[i] - opp_positions)**2).sum(axis=1))\n",
    "            \n",
    "            if len(distances) == 0:\n",
    "                features.append(feat)\n",
    "                continue\n",
    "                \n",
    "            nearest_idx = distances.argmin()\n",
    "            feat['nearest_opp_dist'] = distances[nearest_idx]\n",
    "            feat['num_nearby_opp_3'] = (distances < 3.0).sum()\n",
    "            feat['num_nearby_opp_5'] = (distances < 5.0).sum()\n",
    "            \n",
    "            # Simple closing speed\n",
    "            my_vx = speeds[i] * np.sin(np.deg2rad(directions[i]))\n",
    "            my_vy = speeds[i] * np.cos(np.deg2rad(directions[i]))\n",
    "            opp_speeds = speeds[opp_mask]\n",
    "            opp_dirs = directions[opp_mask]\n",
    "            opp_vx = opp_speeds[nearest_idx] * np.sin(np.deg2rad(opp_dirs[nearest_idx]))\n",
    "            opp_vy = opp_speeds[nearest_idx] * np.cos(np.deg2rad(opp_dirs[nearest_idx]))\n",
    "            \n",
    "            rel_vx = my_vx - opp_vx\n",
    "            rel_vy = my_vy - opp_vy\n",
    "            to_me = positions[i] - opp_positions[nearest_idx]\n",
    "            to_me_norm = to_me / (np.linalg.norm(to_me) + 0.1)\n",
    "            feat['closing_speed_opp'] = -(rel_vx * to_me_norm[0] + rel_vy * to_me_norm[1])\n",
    "\n",
    "            \n",
    "            features.append(feat)\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b9871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_safe_catboost_features(df):\n",
    "    \"\"\"üéØ ONLY SAFE, GENERALIZABLE ADDITIONS\"\"\"\n",
    "    print(\"Adding safe CatBoost features (physics-based only)...\")\n",
    "    \n",
    "    # Player BMI\n",
    "    height_parts = df['player_height'].str.split('-', expand=True)\n",
    "    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n",
    "    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n",
    "    \n",
    "    # Orientation alignment\n",
    "    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n",
    "    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n",
    "    \n",
    "    # Non-linear physics\n",
    "    df['speed_squared'] = df['s'] ** 2\n",
    "    df['dist_squared'] = df['distance_to_ball'] ** 2\n",
    "    \n",
    "    # Angle to target\n",
    "    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n",
    "    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n",
    "    \n",
    "    # Better closing speed calculation\n",
    "    df['velocity_toward_ball'] = (\n",
    "        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n",
    "        df['velocity_y'] * np.sin(df['angle_to_ball'])\n",
    "    )\n",
    "    \n",
    "    print(\"Added 6 safe physics features\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dff66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/4] Loading data...\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "print(\"\\n[1/4] Loading data...\")\n",
    "train_input_files = [config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "train_output_files = [config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n",
    "train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n",
    "test_input = pd.read_csv(config.DATA_DIR / \"test_input.csv\")\n",
    "test_template = pd.read_csv(config.DATA_DIR / \"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf1050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
