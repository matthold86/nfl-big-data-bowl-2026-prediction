{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NFL BIG DATA BOWL 2026 - ENHANCED NN (MINIMAL ADDITIONS)\n",
    "üéØ Starting from 0.61 baseline, adding ONLY safe generalizable features\n",
    "Expected: 0.58-0.60 (modest improvement, no overfit)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIG\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n",
    "    OUTPUT_DIR = Path(\"./outputs\")\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 200\n",
    "    PATIENCE = 30\n",
    "    LEARNING_RATE = 1e-3\n",
    "    \n",
    "    WINDOW_SIZE = 10\n",
    "    HIDDEN_DIM = 128\n",
    "    MAX_FUTURE_HORIZON = 94\n",
    "    \n",
    "    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n",
    "    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n",
    "    \n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(Config.SEED)\n",
    "\n",
    "# ============================================================================\n",
    "# SAFE OPPONENT FEATURES (MINIMAL)\n",
    "# ============================================================================\n",
    "\n",
    "def get_opponent_proximity_simple(input_df):\n",
    "    \"\"\"Only basic opponent proximity - no complex features\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for (gid, pid), group in tqdm(input_df.groupby(['game_id', 'play_id']), \n",
    "                                   desc=\"üèà Opponent proximity\", leave=False):\n",
    "        last = group.sort_values('frame_id').groupby('nfl_id').last()\n",
    "        \n",
    "        if len(last) < 2:\n",
    "            continue\n",
    "            \n",
    "        positions = last[['x', 'y']].values\n",
    "        sides = last['player_side'].values\n",
    "        speeds = last['s'].values\n",
    "        directions = last['dir'].values\n",
    "        \n",
    "        for i, (nid, side) in enumerate(zip(last.index, sides)):\n",
    "            opp_mask = sides != side\n",
    "            \n",
    "            feat = {\n",
    "                'game_id': gid, 'play_id': pid, 'nfl_id': nid,\n",
    "                'nearest_opp_dist': 50.0,\n",
    "                'num_nearby_opp_3': 0,\n",
    "                'num_nearby_opp_5': 0,\n",
    "                'closing_speed_opp': 0.0,\n",
    "            }\n",
    "            \n",
    "            if not opp_mask.any():\n",
    "                features.append(feat)\n",
    "                continue\n",
    "            \n",
    "            opp_positions = positions[opp_mask]\n",
    "            distances = np.sqrt(((positions[i] - opp_positions)**2).sum(axis=1))\n",
    "            \n",
    "            if len(distances) == 0:\n",
    "                features.append(feat)\n",
    "                continue\n",
    "                \n",
    "            nearest_idx = distances.argmin()\n",
    "            feat['nearest_opp_dist'] = distances[nearest_idx]\n",
    "            feat['num_nearby_opp_3'] = (distances < 3.0).sum()\n",
    "            feat['num_nearby_opp_5'] = (distances < 5.0).sum()\n",
    "            \n",
    "            # Simple closing speed\n",
    "            my_vx = speeds[i] * np.sin(np.deg2rad(directions[i]))\n",
    "            my_vy = speeds[i] * np.cos(np.deg2rad(directions[i]))\n",
    "            opp_speeds = speeds[opp_mask]\n",
    "            opp_dirs = directions[opp_mask]\n",
    "            opp_vx = opp_speeds[nearest_idx] * np.sin(np.deg2rad(opp_dirs[nearest_idx]))\n",
    "            opp_vy = opp_speeds[nearest_idx] * np.cos(np.deg2rad(opp_dirs[nearest_idx]))\n",
    "            \n",
    "            rel_vx = my_vx - opp_vx\n",
    "            rel_vy = my_vy - opp_vy\n",
    "            to_me = positions[i] - opp_positions[nearest_idx]\n",
    "            to_me_norm = to_me / (np.linalg.norm(to_me) + 0.1)\n",
    "            feat['closing_speed_opp'] = -(rel_vx * to_me_norm[0] + rel_vy * to_me_norm[1])\n",
    "            \n",
    "            features.append(feat)\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# ============================================================================\n",
    "# ENHANCED FEATURE ENGINEERING (ORIGINAL + SAFE ADDITIONS)\n",
    "# ============================================================================\n",
    "\n",
    "def height_to_feet(height_str):\n",
    "    try:\n",
    "        ft, inches = map(int, str(height_str).split('-'))\n",
    "        return ft + inches/12\n",
    "    except:\n",
    "        return 6.0\n",
    "\n",
    "def add_advanced_features(df):\n",
    "    \"\"\"Original nflnn.py features\"\"\"\n",
    "    print(\"Adding advanced features...\")\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    gcols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    # Distance rate features (3)\n",
    "    if 'distance_to_ball' in df.columns:\n",
    "        df['distance_to_ball_change'] = df.groupby(gcols)['distance_to_ball'].diff().fillna(0)\n",
    "        df['distance_to_ball_accel'] = df.groupby(gcols)['distance_to_ball_change'].diff().fillna(0)\n",
    "        df['time_to_intercept'] = (df['distance_to_ball'] / \n",
    "                                    (np.abs(df['distance_to_ball_change']) + 0.1)).clip(0, 10)\n",
    "    \n",
    "    # Target alignment features (3)\n",
    "    if 'ball_direction_x' in df.columns:\n",
    "        df['velocity_alignment'] = (\n",
    "            df['velocity_x'] * df['ball_direction_x'] +\n",
    "            df['velocity_y'] * df['ball_direction_y']\n",
    "        )\n",
    "        df['velocity_perpendicular'] = (\n",
    "            df['velocity_x'] * (-df['ball_direction_y']) +\n",
    "            df['velocity_y'] * df['ball_direction_x']\n",
    "        )\n",
    "        if 'acceleration_x' in df.columns:\n",
    "            df['accel_alignment'] = (\n",
    "                df['acceleration_x'] * df['ball_direction_x'] +\n",
    "                df['acceleration_y'] * df['ball_direction_y']\n",
    "            )\n",
    "    \n",
    "    # Multi-window rolling (24)\n",
    "    for window in [3, 5, 10]:\n",
    "        for col in ['velocity_x', 'velocity_y', 's', 'a']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_roll{window}'] = df.groupby(gcols)[col].transform(\n",
    "                    lambda x: x.rolling(window, min_periods=1).mean()\n",
    "                )\n",
    "                df[f'{col}_std{window}'] = df.groupby(gcols)[col].transform(\n",
    "                    lambda x: x.rolling(window, min_periods=1).std()\n",
    "                ).fillna(0)\n",
    "    \n",
    "    # Extended lag features (8)\n",
    "    for lag in [4, 5]:\n",
    "        for col in ['x', 'y', 'velocity_x', 'velocity_y']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_lag{lag}'] = df.groupby(gcols)[col].shift(lag).fillna(0)\n",
    "    \n",
    "    # Velocity change features (4)\n",
    "    if 'velocity_x' in df.columns:\n",
    "        df['velocity_x_change'] = df.groupby(gcols)['velocity_x'].diff().fillna(0)\n",
    "        df['velocity_y_change'] = df.groupby(gcols)['velocity_y'].diff().fillna(0)\n",
    "        df['speed_change'] = df.groupby(gcols)['s'].diff().fillna(0)\n",
    "        df['direction_change'] = df.groupby(gcols)['dir'].diff().fillna(0)\n",
    "        df['direction_change'] = df['direction_change'].apply(\n",
    "            lambda x: x if abs(x) < 180 else x - 360 * np.sign(x)\n",
    "        )\n",
    "    \n",
    "    # Field position features (4)\n",
    "    df['dist_from_left'] = df['y']\n",
    "    df['dist_from_right'] = 53.3 - df['y']\n",
    "    df['dist_from_sideline'] = np.minimum(df['dist_from_left'], df['dist_from_right'])\n",
    "    df['dist_from_endzone'] = np.minimum(df['x'], 120 - df['x'])\n",
    "    \n",
    "    # Role-specific features (3)\n",
    "    if 'is_receiver' in df.columns and 'velocity_alignment' in df.columns:\n",
    "        df['receiver_optimality'] = df['is_receiver'] * df['velocity_alignment']\n",
    "        df['receiver_deviation'] = df['is_receiver'] * np.abs(df.get('velocity_perpendicular', 0))\n",
    "    if 'is_coverage' in df.columns and 'closing_speed' in df.columns:\n",
    "        df['defender_closing_speed'] = df['is_coverage'] * df['closing_speed']\n",
    "    \n",
    "    # Time features (2)\n",
    "    df['frames_elapsed'] = df.groupby(gcols).cumcount()\n",
    "    df['normalized_time'] = df.groupby(gcols)['frames_elapsed'].transform(\n",
    "        lambda x: x / (x.max() + 1)\n",
    "    )\n",
    "    \n",
    "    print(f\"Total features after enhancement: {len(df.columns)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_safe_catboost_features(df):\n",
    "    \"\"\"üéØ ONLY SAFE, GENERALIZABLE ADDITIONS\"\"\"\n",
    "    print(\"Adding safe CatBoost features (physics-based only)...\")\n",
    "    \n",
    "    # Player BMI\n",
    "    height_parts = df['player_height'].str.split('-', expand=True)\n",
    "    df['height_inches'] = height_parts[0].astype(float) * 12 + height_parts[1].astype(float)\n",
    "    df['bmi'] = (df['player_weight'] / (df['height_inches']**2)) * 703\n",
    "    \n",
    "    # Orientation alignment\n",
    "    df['orientation_diff'] = np.abs(df['o'] - df['dir'])\n",
    "    df['orientation_diff'] = np.minimum(df['orientation_diff'], 360 - df['orientation_diff'])\n",
    "    \n",
    "    # Non-linear physics\n",
    "    df['speed_squared'] = df['s'] ** 2\n",
    "    df['dist_squared'] = df['distance_to_ball'] ** 2\n",
    "    \n",
    "    # Angle to target\n",
    "    df['angle_diff'] = np.abs(df['o'] - np.degrees(df['angle_to_ball']))\n",
    "    df['angle_diff'] = np.minimum(df['angle_diff'], 360 - df['angle_diff'])\n",
    "    \n",
    "    # Better closing speed calculation\n",
    "    df['velocity_toward_ball'] = (\n",
    "        df['velocity_x'] * np.cos(df['angle_to_ball']) + \n",
    "        df['velocity_y'] * np.sin(df['angle_to_ball'])\n",
    "    )\n",
    "    \n",
    "    print(\"Added 6 safe physics features\")\n",
    "    return df\n",
    "\n",
    "def prepare_sequences_enhanced(input_df, output_df=None, test_template=None, \n",
    "                               is_training=True, window_size=8):\n",
    "    \"\"\"\n",
    "    Prepare sequences with enhanced features (original + safe additions)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PREPARING SEQUENCES WITH ENHANCED FEATURES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Window size: {window_size}\")\n",
    "    \n",
    "    input_df = input_df.copy()\n",
    "    \n",
    "    # Basic features\n",
    "    print(\"Step 1/4: Adding basic features...\")\n",
    "    \n",
    "    input_df['player_height_feet'] = input_df['player_height'].apply(height_to_feet)\n",
    "    \n",
    "    dir_rad = np.deg2rad(input_df['dir'].fillna(0))\n",
    "    delta_t = 0.1\n",
    "    input_df['velocity_x'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.sin(dir_rad)\n",
    "    input_df['velocity_y'] = (input_df['s'] + 0.5 * input_df['a'] * delta_t) * np.cos(dir_rad)\n",
    "    input_df['acceleration_x'] = input_df['a'] * np.sin(dir_rad)\n",
    "    input_df['acceleration_y'] = input_df['a'] * np.cos(dir_rad)\n",
    "    \n",
    "    # Roles\n",
    "    input_df['is_offense'] = (input_df['player_side'] == 'Offense').astype(int)\n",
    "    input_df['is_defense'] = (input_df['player_side'] == 'Defense').astype(int)\n",
    "    input_df['is_receiver'] = (input_df['player_role'] == 'Targeted Receiver').astype(int)\n",
    "    input_df['is_coverage'] = (input_df['player_role'] == 'Defensive Coverage').astype(int)\n",
    "    input_df['is_passer'] = (input_df['player_role'] == 'Passer').astype(int)\n",
    "    \n",
    "    # Physics\n",
    "    mass_kg = input_df['player_weight'].fillna(200.0) / 2.20462\n",
    "    input_df['momentum_x'] = input_df['velocity_x'] * mass_kg\n",
    "    input_df['momentum_y'] = input_df['velocity_y'] * mass_kg\n",
    "    input_df['kinetic_energy'] = 0.5 * mass_kg * (input_df['s'] ** 2)\n",
    "    \n",
    "    # Ball features\n",
    "    if 'ball_land_x' in input_df.columns:\n",
    "        ball_dx = input_df['ball_land_x'] - input_df['x']\n",
    "        ball_dy = input_df['ball_land_y'] - input_df['y']\n",
    "        input_df['distance_to_ball'] = np.sqrt(ball_dx**2 + ball_dy**2)\n",
    "        input_df['angle_to_ball'] = np.arctan2(ball_dy, ball_dx)\n",
    "        input_df['ball_direction_x'] = ball_dx / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['ball_direction_y'] = ball_dy / (input_df['distance_to_ball'] + 1e-6)\n",
    "        input_df['closing_speed'] = (\n",
    "            input_df['velocity_x'] * input_df['ball_direction_x'] +\n",
    "            input_df['velocity_y'] * input_df['ball_direction_y']\n",
    "        )\n",
    "    \n",
    "    # Sort for temporal\n",
    "    input_df = input_df.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id'])\n",
    "    gcols = ['game_id', 'play_id', 'nfl_id']\n",
    "    \n",
    "    # Original lag features (1-3)\n",
    "    for lag in [1, 2, 3]:\n",
    "        input_df[f'x_lag{lag}'] = input_df.groupby(gcols)['x'].shift(lag)\n",
    "        input_df[f'y_lag{lag}'] = input_df.groupby(gcols)['y'].shift(lag)\n",
    "        input_df[f'velocity_x_lag{lag}'] = input_df.groupby(gcols)['velocity_x'].shift(lag)\n",
    "        input_df[f'velocity_y_lag{lag}'] = input_df.groupby(gcols)['velocity_y'].shift(lag)\n",
    "    \n",
    "    # EMA features\n",
    "    input_df['velocity_x_ema'] = input_df.groupby(gcols)['velocity_x'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    input_df['velocity_y_ema'] = input_df.groupby(gcols)['velocity_y'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    input_df['speed_ema'] = input_df.groupby(gcols)['s'].transform(\n",
    "        lambda x: x.ewm(alpha=0.3, adjust=False).mean()\n",
    "    )\n",
    "    \n",
    "    # Advanced features (original)\n",
    "    print(\"Step 2/4: Adding advanced features...\")\n",
    "    input_df = add_advanced_features(input_df)\n",
    "    \n",
    "    # Safe CatBoost additions\n",
    "    print(\"Step 3/4: Adding safe CatBoost features...\")\n",
    "    input_df = add_safe_catboost_features(input_df)\n",
    "    \n",
    "    # Opponent proximity (simple)\n",
    "    print(\"Step 3.5/4: Adding opponent proximity...\")\n",
    "    opp_features = get_opponent_proximity_simple(input_df)\n",
    "    input_df = input_df.merge(opp_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n",
    "    \n",
    "    # Feature list\n",
    "    print(\"Step 4/4: Creating sequences...\")\n",
    "    \n",
    "    feature_cols = [\n",
    "        # Core (9)\n",
    "        'x', 'y', 's', 'a', 'o', 'dir', 'frame_id', 'ball_land_x', 'ball_land_y',\n",
    "        \n",
    "        # Player (4 - added height_inches, bmi)\n",
    "        'player_height_feet', 'player_weight', 'height_inches', 'bmi',\n",
    "        \n",
    "        # Motion (7 - added speed_squared)\n",
    "        'velocity_x', 'velocity_y', 'acceleration_x', 'acceleration_y',\n",
    "        'momentum_x', 'momentum_y', 'kinetic_energy', 'speed_squared',\n",
    "        \n",
    "        # Roles (5)\n",
    "        'is_offense', 'is_defense', 'is_receiver', 'is_coverage', 'is_passer',\n",
    "        \n",
    "        # Ball (7 - added dist_squared, velocity_toward_ball)\n",
    "        'distance_to_ball', 'dist_squared', 'angle_to_ball', \n",
    "        'ball_direction_x', 'ball_direction_y', 'closing_speed', 'velocity_toward_ball',\n",
    "        \n",
    "        # Angles (2 - NEW)\n",
    "        'orientation_diff', 'angle_diff',\n",
    "        \n",
    "        # Opponent (4 - NEW)\n",
    "        'nearest_opp_dist', 'num_nearby_opp_3', 'num_nearby_opp_5', 'closing_speed_opp',\n",
    "        \n",
    "        # Original temporal (15)\n",
    "        'x_lag1', 'y_lag1', 'velocity_x_lag1', 'velocity_y_lag1',\n",
    "        'x_lag2', 'y_lag2', 'velocity_x_lag2', 'velocity_y_lag2',\n",
    "        'x_lag3', 'y_lag3', 'velocity_x_lag3', 'velocity_y_lag3',\n",
    "        'velocity_x_ema', 'velocity_y_ema', 'speed_ema',\n",
    "        \n",
    "        # Distance rate (3)\n",
    "        'distance_to_ball_change', 'distance_to_ball_accel', 'time_to_intercept',\n",
    "        \n",
    "        # Target alignment (3)\n",
    "        'velocity_alignment', 'velocity_perpendicular', 'accel_alignment',\n",
    "        \n",
    "        # Multi-window rolling (24)\n",
    "        'velocity_x_roll3', 'velocity_x_std3', 'velocity_y_roll3', 'velocity_y_std3',\n",
    "        's_roll3', 's_std3', 'a_roll3', 'a_std3',\n",
    "        'velocity_x_roll5', 'velocity_x_std5', 'velocity_y_roll5', 'velocity_y_std5',\n",
    "        's_roll5', 's_std5', 'a_roll5', 'a_std5',\n",
    "        'velocity_x_roll10', 'velocity_x_std10', 'velocity_y_roll10', 'velocity_y_std10',\n",
    "        's_roll10', 's_std10', 'a_roll10', 'a_std10',\n",
    "        \n",
    "        # Extended lags (8)\n",
    "        'x_lag4', 'y_lag4', 'velocity_x_lag4', 'velocity_y_lag4',\n",
    "        'x_lag5', 'y_lag5', 'velocity_x_lag5', 'velocity_y_lag5',\n",
    "        \n",
    "        # Velocity changes (4)\n",
    "        'velocity_x_change', 'velocity_y_change', 'speed_change', 'direction_change',\n",
    "        \n",
    "        # Field position (2)\n",
    "        'dist_from_sideline', 'dist_from_endzone',\n",
    "        \n",
    "        # Role-specific (3)\n",
    "        'receiver_optimality', 'receiver_deviation', 'defender_closing_speed',\n",
    "        \n",
    "        # Time (2)\n",
    "        'frames_elapsed', 'normalized_time',\n",
    "    ]\n",
    "    \n",
    "    # Filter to existing\n",
    "    feature_cols = [c for c in feature_cols if c in input_df.columns]\n",
    "    print(f\"Using {len(feature_cols)} features (was ~87, now ~97)\")\n",
    "    \n",
    "    # CREATE SEQUENCES\n",
    "    input_df.set_index(['game_id', 'play_id', 'nfl_id'], inplace=True)\n",
    "    grouped = input_df.groupby(level=['game_id', 'play_id', 'nfl_id'])\n",
    "    \n",
    "    target_rows = output_df if is_training else test_template\n",
    "    target_groups = target_rows[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n",
    "    \n",
    "    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = [], [], [], [], []\n",
    "    \n",
    "    for _, row in tqdm(target_groups.iterrows(), total=len(target_groups), desc=\"Creating sequences\"):\n",
    "        key = (row['game_id'], row['play_id'], row['nfl_id'])\n",
    "        \n",
    "        try:\n",
    "            group_df = grouped.get_group(key)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        input_window = group_df.tail(window_size)\n",
    "        \n",
    "        if len(input_window) < window_size:\n",
    "            if is_training:\n",
    "                continue\n",
    "            pad_len = window_size - len(input_window)\n",
    "            pad_df = pd.DataFrame(np.nan, index=range(pad_len), columns=input_window.columns)\n",
    "            input_window = pd.concat([pad_df, input_window], ignore_index=True)\n",
    "        \n",
    "        input_window = input_window.fillna(group_df.mean(numeric_only=True))\n",
    "        seq = input_window[feature_cols].values\n",
    "        \n",
    "        if np.isnan(seq).any():\n",
    "            if is_training:\n",
    "                continue\n",
    "            seq = np.nan_to_num(seq, nan=0.0)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        \n",
    "        if is_training:\n",
    "            out_grp = output_df[\n",
    "                (output_df['game_id']==row['game_id']) &\n",
    "                (output_df['play_id']==row['play_id']) &\n",
    "                (output_df['nfl_id']==row['nfl_id'])\n",
    "            ].sort_values('frame_id')\n",
    "            \n",
    "            last_x = input_window.iloc[-1]['x']\n",
    "            last_y = input_window.iloc[-1]['y']\n",
    "            \n",
    "            dx = out_grp['x'].values - last_x\n",
    "            dy = out_grp['y'].values - last_y\n",
    "            \n",
    "            targets_dx.append(dx)\n",
    "            targets_dy.append(dy)\n",
    "            targets_frame_ids.append(out_grp['frame_id'].values)\n",
    "        \n",
    "        sequence_ids.append({\n",
    "            'game_id': key[0],\n",
    "            'play_id': key[1],\n",
    "            'nfl_id': key[2],\n",
    "            'frame_id': input_window.iloc[-1]['frame_id']\n",
    "        })\n",
    "    \n",
    "    print(f\"Created {len(sequences)} sequences with {len(feature_cols)} features each\")\n",
    "    \n",
    "    if is_training:\n",
    "        return sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids\n",
    "    return sequences, sequence_ids\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL & LOSS (Same as baseline)\n",
    "# ============================================================================\n",
    "\n",
    "class TemporalHuber(nn.Module):\n",
    "    def __init__(self, delta=0.5, time_decay=0.03):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.time_decay = time_decay\n",
    "    \n",
    "    def forward(self, pred, target, mask):\n",
    "        err = pred - target\n",
    "        abs_err = torch.abs(err)\n",
    "        huber = torch.where(abs_err <= self.delta, 0.5 * err * err, \n",
    "                           self.delta * (abs_err - 0.5 * self.delta))\n",
    "        \n",
    "        if self.time_decay > 0:\n",
    "            L = pred.size(1)\n",
    "            t = torch.arange(L, device=pred.device).float()\n",
    "            weight = torch.exp(-self.time_decay * t).view(1, L)\n",
    "            huber, mask = huber * weight, mask * weight\n",
    "        \n",
    "        return (huber * mask).sum() / (mask.sum() + 1e-8)\n",
    "\n",
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, horizon):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.pool_ln = nn.LayerNorm(128)\n",
    "        self.pool_attn = nn.MultiheadAttention(128, num_heads=4, batch_first=True)\n",
    "        self.pool_query = nn.Parameter(torch.randn(1, 1, 128))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 128), nn.GELU(), nn.Dropout(0.2), nn.Linear(128, horizon)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h, _ = self.gru(x)\n",
    "        B = h.size(0)\n",
    "        q = self.pool_query.expand(B, -1, -1)\n",
    "        ctx, _ = self.pool_attn(q, self.pool_ln(h), self.pool_ln(h))\n",
    "        out = self.head(ctx.squeeze(1))\n",
    "        return torch.cumsum(out, dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_targets(batch_axis, max_h):\n",
    "    tensors, masks = [], []\n",
    "    for arr in batch_axis:\n",
    "        L = len(arr)\n",
    "        padded = np.pad(arr, (0, max_h - L), constant_values=0).astype(np.float32)\n",
    "        mask = np.zeros(max_h, dtype=np.float32)\n",
    "        mask[:L] = 1.0\n",
    "        tensors.append(torch.tensor(padded))\n",
    "        masks.append(torch.tensor(mask))\n",
    "    return torch.stack(tensors), torch.stack(masks)\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, input_dim, horizon, config):\n",
    "    device = config.DEVICE\n",
    "    model = SeqModel(input_dim, horizon).to(device)\n",
    "    \n",
    "    criterion = TemporalHuber(delta=0.5, time_decay=0.03)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=False)\n",
    "    \n",
    "    # Batches\n",
    "    train_batches = []\n",
    "    for i in range(0, len(X_train), config.BATCH_SIZE):\n",
    "        end = min(i + config.BATCH_SIZE, len(X_train))\n",
    "        bx = torch.tensor(np.stack(X_train[i:end]).astype(np.float32))\n",
    "        by, bm = prepare_targets([y_train[j] for j in range(i, end)], horizon)\n",
    "        train_batches.append((bx, by, bm))\n",
    "    \n",
    "    val_batches = []\n",
    "    for i in range(0, len(X_val), config.BATCH_SIZE):\n",
    "        end = min(i + config.BATCH_SIZE, len(X_val))\n",
    "        bx = torch.tensor(np.stack(X_val[i:end]).astype(np.float32))\n",
    "        by, bm = prepare_targets([y_val[j] for j in range(i, end)], horizon)\n",
    "        val_batches.append((bx, by, bm))\n",
    "    \n",
    "    best_loss, best_state, bad = float('inf'), None, 0\n",
    "    \n",
    "    for epoch in range(1, config.EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for bx, by, bm in train_batches:\n",
    "            bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n",
    "            pred = model(bx)\n",
    "            loss = criterion(pred, by, bm)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for bx, by, bm in val_batches:\n",
    "                bx, by, bm = bx.to(device), by.to(device), bm.to(device)\n",
    "                pred = model(bx)\n",
    "                val_losses.append(criterion(pred, by, bm).item())\n",
    "        \n",
    "        train_loss, val_loss = np.mean(train_losses), np.mean(val_losses)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch}: train={train_loss:.4f}, val={val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= config.PATIENCE:\n",
    "                print(f\"  Early stop at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    \n",
    "    return model, best_loss\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENHANCED NN: BASELINE + 10 SAFE FEATURES\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nüéØ Adding only physics-based, generalizable features\")\n",
    "    \n",
    "    # Load\n",
    "    print(\"\\n[1/4] Loading data...\")\n",
    "    train_input_files = [config.DATA_DIR / f\"train/input_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "    train_output_files = [config.DATA_DIR / f\"train/output_2023_w{w:02d}.csv\" for w in range(1, 19)]\n",
    "    train_input = pd.concat([pd.read_csv(f) for f in train_input_files if f.exists()])\n",
    "    train_output = pd.concat([pd.read_csv(f) for f in train_output_files if f.exists()])\n",
    "    test_input = pd.read_csv(config.DATA_DIR / \"test_input.csv\")\n",
    "    test_template = pd.read_csv(config.DATA_DIR / \"test.csv\")\n",
    "    \n",
    "    # Prepare\n",
    "    print(\"\\n[2/4] Preparing with enhanced features...\")\n",
    "    sequences, targets_dx, targets_dy, targets_frame_ids, sequence_ids = prepare_sequences_enhanced(\n",
    "        train_input, train_output, is_training=True, window_size=config.WINDOW_SIZE\n",
    "    )\n",
    "    \n",
    "    sequences = np.array(sequences, dtype=object)\n",
    "    targets_dx = np.array(targets_dx, dtype=object)\n",
    "    targets_dy = np.array(targets_dy, dtype=object)\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n[3/4] Training enhanced models...\")\n",
    "    groups = np.array([d['game_id'] for d in sequence_ids])\n",
    "    gkf = GroupKFold(n_splits=config.N_FOLDS)\n",
    "    \n",
    "    models_x, models_y, scalers = [], [], []\n",
    "    \n",
    "    for fold, (tr, va) in enumerate(gkf.split(sequences, groups=groups), 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold}/{config.N_FOLDS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        X_tr, X_va = sequences[tr], sequences[va]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(np.vstack([s for s in X_tr]))\n",
    "        \n",
    "        X_tr_sc = np.stack([scaler.transform(s) for s in X_tr])\n",
    "        X_va_sc = np.stack([scaler.transform(s) for s in X_va])\n",
    "        \n",
    "        # Train X\n",
    "        print(\"Training X-axis model...\")\n",
    "        mx, loss_x = train_model(\n",
    "            X_tr_sc, targets_dx[tr], X_va_sc, targets_dx[va],\n",
    "            X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config\n",
    "        )\n",
    "        \n",
    "        # Train Y\n",
    "        print(\"Training Y-axis model...\")\n",
    "        my, loss_y = train_model(\n",
    "            X_tr_sc, targets_dy[tr], X_va_sc, targets_dy[va],\n",
    "            X_tr[0].shape[-1], config.MAX_FUTURE_HORIZON, config\n",
    "        )\n",
    "        \n",
    "        models_x.append(mx)\n",
    "        models_y.append(my)\n",
    "        scalers.append(scaler)\n",
    "        \n",
    "        print(f\"\\nFold {fold} - X loss: {loss_x:.5f}, Y loss: {loss_y:.5f}\")\n",
    "    \n",
    "    # Test predictions\n",
    "    print(\"\\n[4/4] Creating test predictions...\")\n",
    "    test_sequences, test_ids = prepare_sequences_enhanced(\n",
    "        test_input, test_template=test_template, is_training=False, window_size=config.WINDOW_SIZE\n",
    "    )\n",
    "    \n",
    "    X_test = np.array(test_sequences, dtype=object)\n",
    "    x_last = np.array([s[-1, 0] for s in X_test])\n",
    "    y_last = np.array([s[-1, 1] for s in X_test])\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    all_dx, all_dy = [], []\n",
    "    for mx, my, sc in zip(models_x, models_y, scalers):\n",
    "        X_sc = np.stack([sc.transform(s) for s in X_test])\n",
    "        X_t = torch.tensor(X_sc.astype(np.float32)).to(config.DEVICE)\n",
    "        \n",
    "        mx.eval()\n",
    "        my.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            all_dx.append(mx(X_t).cpu().numpy())\n",
    "            all_dy.append(my(X_t).cpu().numpy())\n",
    "    \n",
    "    ens_dx = np.mean(all_dx, axis=0)\n",
    "    ens_dy = np.mean(all_dy, axis=0)\n",
    "    \n",
    "    # Create submission\n",
    "    rows = []\n",
    "    H = ens_dx.shape[1]\n",
    "    \n",
    "    for i, sid in enumerate(test_ids):\n",
    "        fids = test_template[\n",
    "            (test_template['game_id'] == sid['game_id']) &\n",
    "            (test_template['play_id'] == sid['play_id']) &\n",
    "            (test_template['nfl_id'] == sid['nfl_id'])\n",
    "        ]['frame_id'].sort_values().tolist()\n",
    "        \n",
    "        for t, fid in enumerate(fids):\n",
    "            tt = min(t, H - 1)\n",
    "            px = np.clip(x_last[i] + ens_dx[i, tt], 0, 120)\n",
    "            py = np.clip(y_last[i] + ens_dy[i, tt], 0, 53.3)\n",
    "            \n",
    "            rows.append({\n",
    "                'id': f\"{sid['game_id']}_{sid['play_id']}_{sid['nfl_id']}_{fid}\",\n",
    "                'x': px,\n",
    "                'y': py\n",
    "            })\n",
    "    \n",
    "    submission = pd.DataFrame(rows)\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ENHANCED PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úì Saved submission_plus.csv\")\n",
    "    print(f\"  Rows: {len(submission)}\")\n",
    "    print(f\"\\nüìä SAFE ADDITIONS:\")\n",
    "    print(f\"  1. BMI (player characteristic)\")\n",
    "    print(f\"  2. orientation_diff (body vs movement)\")\n",
    "    print(f\"  3. speed_squared (non-linear physics)\")\n",
    "    print(f\"  4. dist_squared (non-linear distance)\")\n",
    "    print(f\"  5. angle_diff (orientation to target)\")\n",
    "    print(f\"  6. velocity_toward_ball (improved closing)\")\n",
    "    print(f\"  7-10. Opponent proximity (4 features)\")\n",
    "    print(f\"\\nüéØ Expected: 0.58-0.60 (modest improvement, no overfit)\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13825858,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
