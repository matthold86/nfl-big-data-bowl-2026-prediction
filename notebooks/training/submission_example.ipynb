{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission Server Example\n",
        "\n",
        "This notebook shows how to use the submission server for Kaggle competition.\n",
        "\n",
        "## How the Submission Server Works\n",
        "\n",
        "The NFL Big Data Bowl uses a **server-based evaluation API**:\n",
        "1. Your notebook runs as a server that receives test data in batches\n",
        "2. Each batch must return predictions within 5 minutes\n",
        "3. Kaggle's evaluation system calls your server repeatedly until all data is processed\n",
        "\n",
        "## Setup\n",
        "\n",
        "Your predict function must:\n",
        "- Accept: `test` (Polars DataFrame) and `test_input` (Polars DataFrame)\n",
        "- Return: Polars DataFrame with 'x' and 'y' columns\n",
        "- Respond within 5 minutes per batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import torch\n",
        "from pipeline.submission_server import create_submission_server, run_submission_server\n",
        "from pipeline.save_model import load_model_ensemble\n",
        "from pipeline.models import SeqModel, prepare_targets\n",
        "from pipeline.config import Config\n",
        "\n",
        "# Initialize config\n",
        "config = Config()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Prediction Function\n",
        "\n",
        "The predict function is called by the server for each batch of test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models (do this once at the start, before predict function)\n",
        "# Models will be reused across all predict calls\n",
        "saved_model = load_model_ensemble('models/nn_baseline.0')\n",
        "\n",
        "models_x, models_y = [], []\n",
        "for i in range(saved_model['num_folds']):\n",
        "    # Load X-axis model\n",
        "    model_x = SeqModel(input_dim=YOUR_FEATURE_DIM, horizon=config.MAX_FUTURE_HORIZON)\n",
        "    model_x.load_state_dict(torch.load(saved_model['models_x_files'][i], map_location=config.DEVICE))\n",
        "    model_x.eval()\n",
        "    models_x.append(model_x)\n",
        "    \n",
        "    # Load Y-axis model\n",
        "    model_y = SeqModel(input_dim=YOUR_FEATURE_DIM, horizon=config.MAX_FUTURE_HORIZON)\n",
        "    model_y.load_state_dict(torch.load(saved_model['models_y_files'][i], map_location=config.DEVICE))\n",
        "    model_y.eval()\n",
        "    models_y.append(model_y)\n",
        "\n",
        "scaler = saved_model['scalers']\n",
        "print(f\"Loaded {len(models_x)} models\")\n",
        "\n",
        "# Placeholder: Replace with your actual prediction logic\n",
        "def predict_fn(test: pl.DataFrame, test_input: pl.DataFrame) -> pl.DataFrame:\n",
        "    \"\"\"\n",
        "    Prediction function for Kaggle competition.\n",
        "    \n",
        "    Called by the server for each batch of test data.\n",
        "    \n",
        "    Args:\n",
        "        test: Test data as Polars DataFrame\n",
        "        test_input: Additional input data as Polars DataFrame\n",
        "    \n",
        "    Returns:\n",
        "        Polars DataFrame with 'x' and 'y' columns\n",
        "    \"\"\"\n",
        "    # TODO: Implement prediction logic\n",
        "    # 1. Feature engineering on test/test_input data\n",
        "    # 2. Sequence preparation (using saved config)\n",
        "    # 3. Scaling (using saved scaler)\n",
        "    # 4. Model inference (ensembling all folds)\n",
        "    # 5. Post-processing (cumulative sum, clipping to field bounds)\n",
        "    # 6. Format predictions\n",
        "    \n",
        "    # Placeholder\n",
        "    predictions = pl.DataFrame({\n",
        "        'x': [0.0] * len(test),\n",
        "        'y': [0.0] * len(test)\n",
        "    })\n",
        "    \n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start the Server\n",
        "\n",
        "The server automatically detects whether you're running in competition mode or local testing mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For local testing (use gateway to simulate competition environment)\n",
        "# server = run_submission_server(predict_fn, gateway_path=('/path/to/test/data/',))\n",
        "\n",
        "# For competition submission (auto-detects KAGGLE_IS_COMPETITION_RERUN environment variable)\n",
        "# server = run_submission_server(predict_fn)\n",
        "\n",
        "# Or create server manually for more control:\n",
        "# server = create_submission_server(predict_fn)\n",
        "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "#     server.serve()  # Start server for competition\n",
        "# else:\n",
        "#     server.run_local_gateway(('/path/to/test/data/',))  # Local testing\n",
        "\n",
        "print(\"Server setup complete. Uncomment lines above to start the server.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
